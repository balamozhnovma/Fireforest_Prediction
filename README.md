Решим задачу регрессии - прогнозирование площади лесных пожаров.

Воспользуемся датасетом Forest Fires Data Set (UCI). Он содержит следующие признаки:
* X - координата X пожара
* Y - координата Y пожара
* month - месяц пожара
* day - день недели пожара
* FFMC - индекс FFMC из системы FWI
* DMC - индекс DMC из системы FWI
* DC - индекс DC из системы FWI
* ISI - индекс ISI из системы FWI
* temp - температура
* RH - относительная влажность
* wind - скорость ветра
* rain - дождь
* area - площадь выгоревшего леса

Файлы проекта:
    * requirements.txt - описание зависимостей
    * eda.py - EDA 
    * dataloader.py - обработка данных и разбиение на тест и трейн
    * Forestfires_Prediction.py - обучение моделей
    * dvc.yaml - DVC пайплайн

Реализуем стандартный пайплайн машинного обучения:
    1. EDA и обработка данных (eda.py)
        * Посмотрим на распределение целевой переменной. 
            Видим много нулей и редкие выбросы.
        * Посмотрим на взаимосвязь целевой переменной с месяцем, климатическими условиями и регионом. 
            Видно, что в мае и декабре самые большие по площади пожары. При этом в мае широкий разброс целевой переменной. 
            Пожары возникают, когда нет дождя (за исключением нескольких выбросов).
            Видна динамика: чем выше температура, тем чаще возникают пожары и тем больше их площадь. 
            Аналогично, чем выше относительная влажность, тем реже и с меньшей площадью возникают лесные пожары.
            Скорость ветра слабо коррелирует с целевой переменной.
            Чаще всего пожары возникают в регионе с координатами X от 2 до 4, Y = 4, при этом площадь пожара небольшая.
        * Посмотрим на наличие пропусков
        * Посмотрим на наличие категориальных признаков.
            Их всего два: месяц и день недели. Закодируем их с помощью OneHotEncoder.
    2. Разобьем выборку на тест и трейн (dataloader.py)
    3. Обучение моделей (Forestfires_Prediction.py)
        * Запустим эксперимент и обучим Random Forest в дочернем
            Он показал аномально высокие значения RMSE из-за выбросов. 
        * Обработаем выбросы и посмотрим на результат
            RMSE стал значительно ниже. Залогируем результат, параметры модели и саму модель.
        * Запустим второй дочерний эксперимент и обучим градиентный бустинг.
            Он показал результаты немного хуже, чем Random Forest, скорее всего, из-за малого числа n_estimators. Залогируем результат, параметры модели и саму модель.
    3. Подберем гиперпараметры для XGBoost  помощью Optuna.
            Тюнинг улучшил показания модели и RMSE снизился. Тюнингованый XGBoost превзошел Random Forest.
